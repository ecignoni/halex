{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import gc\n",
    "\n",
    "import metatensor\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from halex.decomposition import EquivariantPCA\n",
    "from halex.models import RidgeOnEnergiesAndLowdinMultipleMolecules  # ByMO\n",
    "from halex.rotations import ClebschGordanReal\n",
    "from halex.train_utils import (\n",
    "    compute_features,\n",
    "    coupled_fock_matrix_from_multiple_molecules,\n",
    "    load_batched_dataset,\n",
    "    load_molecule_scf_datasets,\n",
    ")\n",
    "from halex.utils import drop_target_samples\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset for both STO-3G and def2-TZVP basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains the frames, orbitals, Fock matrix, overlap matrix, orthogonalized Fock matrix and its block decomposition in `metatensor` format, eigenvalues and eigenvectors, and LÃ¶wdin charges in the minimal basis STO-3G and the fully converged def2-TZVP basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_molecule_datasets(mol: str, cg: ClebschGordanReal, indices: np.ndarray):\n",
    "    \"\"\"\n",
    "    Load the SCFData objects storing data for a single molecule,\n",
    "    in both a small basis and a big basis\n",
    "    \"\"\"\n",
    "    coords_path = f\"CH-dataset/{mol}/coords_{mol}_1000.xyz\"\n",
    "    small_basis_path = f\"CH-dataset/{mol}/b3lyp_STO-3G/\"\n",
    "    big_basis_path = f\"CH-dataset/{mol}/b3lyp_def2tzvp/\"\n",
    "\n",
    "    sb_data, bb_data = load_molecule_scf_datasets(\n",
    "        coords_path=coords_path,\n",
    "        small_basis_path=small_basis_path,\n",
    "        big_basis_path=big_basis_path,\n",
    "        cg=cg,\n",
    "        train_indices=indices,\n",
    "    )\n",
    "\n",
    "    return sb_data, bb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ClebschGordanReal(4)\n",
    "\n",
    "molecules = [\n",
    "    \"ethane\",\n",
    "    \"ethene\",\n",
    "    # \"butadiene\",\n",
    "    # \"hexane\",\n",
    "    # \"hexatriene\",\n",
    "    # \"isoprene\",\n",
    "    # \"styrene\",\n",
    "]\n",
    "\n",
    "indices = np.arange(1000)\n",
    "np.random.shuffle(indices)\n",
    "valid_indices = indices[-200:]\n",
    "indices = indices[:500]\n",
    "np.save(\"train_output/train_indices.npy\", indices)\n",
    "np.save(\"train_output/valid_indices.npy\", valid_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    mol: load_molecule_datasets(mol, cg=cg, indices=indices) for mol in molecules\n",
    "}\n",
    "\n",
    "valid_datasets = {\n",
    "    mol: load_molecule_datasets(mol, cg=cg, indices=valid_indices) for mol in molecules\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build features to learn the Hamiltonian we use the atom-centred equivariant representation $\\ket{\\overline{\\rho_i ^{\\otimes 2} ; \\sigma ; \\lambda \\mu}}$ to learn the orbital interactions on the same centre, $H_{ii}$ terms and the two-centred equivariant representation $\\ket{\\overline{\\rho_{ij} ^{\\otimes 1} ; \\sigma ; \\lambda \\mu}}$  to learn the the orbital interactions on two different centres, $H_{ij}$ terms. We have used the `librascal` library to compute these features and converted them to store in the `metatensor` format.\n",
    "\n",
    "We then reduce the dimensionality of these features using PCA and retain up to 200 principal components for each symmetry block.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rascal_hypers = {\n",
    "    \"interaction_cutoff\": 3.5,\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"max_radial\": 6,\n",
    "    \"max_angular\": 4,\n",
    "    \"gaussian_sigma_constant\": 0.2,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"compute_gradients\": False,\n",
    "}\n",
    "\n",
    "feats = compute_features(datasets, rascal_hypers=rascal_hypers, cg=cg, lcut=2)\n",
    "gc.collect()\n",
    "\n",
    "epca = EquivariantPCA(n_components=200).fit(metatensor.join(feats, axis=\"samples\"))\n",
    "\n",
    "feats = [epca.transform(feats_) for feats_ in feats]\n",
    "gc.collect()\n",
    "\n",
    "epca.save(\"train_output/epca.npz\")\n",
    "\n",
    "valid_feats = compute_features(\n",
    "    valid_datasets, rascal_hypers=rascal_hypers, cg=cg, lcut=2, epca=epca\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batched dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nelec_dict = {\"H\": 1.0, \"C\": 6.0}\n",
    "\n",
    "multimol_datasets = [\n",
    "    load_batched_dataset(\n",
    "        scf_datasets=data,\n",
    "        feats=feat,\n",
    "        nelec_dict=nelec_dict,\n",
    "        batch_size=100,\n",
    "        lowdin_charges_by_MO=False,\n",
    "        # lowdin_mo_indices=indices,\n",
    "    )\n",
    "    for data, feat in zip(datasets.values(), feats)\n",
    "]\n",
    "\n",
    "valid_multimol_datasets = [\n",
    "    load_batched_dataset(\n",
    "        scf_datasets=data,\n",
    "        feats=feat,\n",
    "        nelec_dict=nelec_dict,\n",
    "        batch_size=50,\n",
    "        lowdin_charges_by_MO=False,\n",
    "        # lowdin_mo_indices=indices,\n",
    "    )\n",
    "    for data, feat in zip(valid_datasets.values(), valid_feats)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Change to the Coupled basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the block decomposed Hamiltonian to a coupled basis and drop samples that are not present in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_coupled = coupled_fock_matrix_from_multiple_molecules(datasets.values())\n",
    "targ_coupled = drop_target_samples(\n",
    "    metatensor.join(feats, axis=\"samples\"), targ_coupled, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a symmetry adapted model of the minimal basis (STO-3G) Hamiltonian and train it against a fully converged def2-TZVP basis, using the eigenvalues and partial charges as indirect targets. The model is initialized from the weights obtained by the analytical solution of the ridge regression model (symmetry adapted) that uses as target the minimal basis Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RidgeOnEnergiesAndLowdinMultipleMolecules(\n",
    "    coupled_tmap=targ_coupled,\n",
    "    features=metatensor.join(feats, axis=\"samples\"),\n",
    "    alpha=1e-14,\n",
    "    dump_dir=\"train_output\",\n",
    "    bias=False,\n",
    ")\n",
    "\n",
    "model.fit_ridge_analytical(\n",
    "    features=metatensor.join(feats, axis=\"samples\"),\n",
    "    targets=targ_coupled,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_datasets=multimol_datasets,\n",
    "    valid_datasets=valid_multimol_datasets,\n",
    "    epochs=20_000,\n",
    "    optim_kwargs=dict(lr=1),\n",
    "    verbose=10,\n",
    "    dump=50,\n",
    ")\n",
    "\n",
    "model.dump_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
